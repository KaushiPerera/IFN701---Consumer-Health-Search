\documentclass[]{article}
\usepackage{graphicx}

%opening
\title{Annotated Bibliography}
\author{Kaushi Perera}

\begin{document}

\maketitle


\section{Ye, Z., Gwizdka, J., Lopes, C. T., \& Zhang, Y. (2017). Towards understanding consumers' quality evaluation of online health information: A case study. Proceedings of the Association for Information Science and Technology, 54(1), 838-839.}

This case study investigated how consumers evaluate quality of online health information. The approach of this study has been to use 'eye-tracking' and conducting 'retrospective interviews' in order to investigate different interface elements which are being used by consumers' to evaluate quality and also to investigate whether differences in individuals, such as eHealth literacy, personality, demographic facts and familiarity with health topics have any influence on consumers' behaviour. 12 lay people participated in the study; they were presented with five predefined tasks related to health information search; for each task they were shown 3 preselected web pages and asked if they would recommend those to their family or friends. 

The authors hand-picked results for 2 participants (because of opposite patterns shown in eye glaze and fixation). They observed that, the first participant had viewed the web page content as a F-shaped pattern with fixations focused on the main text content; in contrast the second participant had viewed it in an atypical pattern with scattered fixations. The choice made on this page, time on task, time on page, count of links clicked on and background information (eHEALS and TIPI scores) were compared to analyse the performance of the two participants. In conclusion, the authors noted that the participant with lower eHEALS score is tend to spend a longer time on the task and on the web page than the other participant with a higher eHEALS score. Therefore, eye-movement patterns were dependent on facts, such as familiarity with the health topic, health literacy and demographic factors.               

The authors also have formulated a few hypotheses for future studies:

1. Consumers’ with comparably lower eHealth literacy are tend to: 

H1a. ‘spend more time on quality evaluation’
H1b: ‘rely more on relevance than on quality indicators’  

2. Regarding health-related web page quality:

H2a: ‘Consumers with considerably lower eHealth literacy tend to rely more on the main content of a webpage than on quality indicators’
H2b: ‘Consumers with considerably higher eHealth literacy are able to take advantage of quality indicators’ 

\textbf{Limitations}

Their observations are limited by the fact that just 2 participants were studied. Also, in their analysis the authors did not account for the possibility that the participant with a non-focused eye glazing was distracted and not interested in the task.

\section{Lopes, C. T., \& Fernandes, T. A. (2016, September). Health Suggestions: A Chrome Extension to Help Laypersons Search for Health Information. In International Conference of the Cross-Language Evaluation Forum for European Languages (pp. 241-246). Springer, Cham.}

This study has investigated how providing health query suggestions to consumers will be useful in successful health information retrieval. The study has provided query suggestions in both Portuguese and English based on the initial query's language. Health suggestions were provided in three search engines which are Google, Bing and Yahoo. Therefore, the ultimate aim was to provide consumers with a mechanism which aids consumers in retrieving high-quality health information which will also fit with their health expertise. The approach of the study has been to implement health query suggestions in Google Chrome as a ‘Google Chrome extension’ and then to reach the three search engines. A health suggestion query panel was presented when matches were identified between health suggestions and user queries. Users were able to search for suggested queries (a new search was performed), switch search engines (same search was performed in the new search engine), minimise/maximise the panel, close the panel and navigate to the options page (turn the extension on/off, (dis)allow logging, opt for a local or remote database, specify queries’ language or ask the extension to automatically detect it). Two modules were used in the system; 'Suggestion engine' generated suggestions based on Consumer Health Vocabulary (CHV) which contains links between everyday health-related terms and technical terms; 'Login engine' which consisted of the extension and a server, studied user health search behaviour by tracking different actions, such as time spent on Health Suggestions’ panel, visited web pages, time on web page, number of scroll events, clicks on the extension’s panel, copy/cut events etc. performed by user while searching. 

36 students participated in the study; first group of students received assistance via Health Suggestions; second group was unassisted; health topics for the task were selected randomly from the topics mentioned by 20 laypeople (no medical expertise); participants performed four tasks; for each task they formulated three queries; they were asked to save the most relevant documents from the top 10 results of each query; at the end of each task assisted participants explained how they used Health Suggestions (clicked on them, used terms from one of the suggestions, used terms from several suggestions), why the suggestions were considered useful and assessed the utility of the Health Suggestions. The number of relevant documents retrieved and users' opinions towards the task were used to determine the success of the search. The user satisfaction was scaled from 1 to 5; 4 participants (11\%) classified satisfaction as 3; 26 participants (72\%) classified satisfaction as 4; 6 participants (17\%) classified satisfaction as 5. The authors also evaluated health suggestions based on four research questions:

\textbf{(1) How are suggestions used?}: According to the assisted participants' group; query suggestions were provided for 71\% of the issued queries; in 27\% of these cases users clicked on suggestion; in 15\% of the cases users extracted terms from the suggestions and included them in their next query; in 4\% of the cases users extracted terms from several suggestions.           
 
\textbf{(2) Why are suggestions used?}: Five main reasons were observed; in 35\% of the cases because they presented synonyms, in 37\% of the cases because they presented alternatives in medico-scientific terminology, in 24\% of the cases because they suggested English terms and in 3\% of the cases because of the lay terminology. 
 
\textbf{(3) How do users assess the utility of the suggestions provided by the system?}: Have used a scale in a range of 1-3; 35\% of the queries were considered useful; 33\% partially useful; 29\% were useless.   

\textbf{(4)Do the suggestions lead to a more successful search?}: The average number of relevant documents saved were observed; the average was 16.3 for the assisted group and 14.1 for the unassisted group. The overall task success was scaled from 1 to 5; the mean value was for 4 for the assisted group and 5 for the unassisted group. However, this difference was not considered as significant.   

In conclusion, health query suggestions from the tool were well accepted by the users, both lay terms and medico-scientific term suggestions in Health Suggestions lead to more successful searches; the utility of a multilingual and multi-terminology approach is important and useful to retrieve a huge number of relevant documents.     

\section{Silva, R., \& Lopes, C. (2016). The Effectiveness of Query Expansion when searching for Health related Content: InfoLab at CLEF eHealth 2016. In CLEF (Working Notes) (pp. 130-142).}

This study investigated how query expansion (supplementing the original query with additional terms) will aid laypeople in improving initial queries and then the overall retrieval performance. The impact of query expansion can be determined by evaluating the set of ranked list of documents retrieved from a recommended test collection. Two sub tasks, ad-hoc search (treating each query individually) and query variation (treating a group of query variations as one query) were performed; ClueWeb12 B13 Dataset was used as the document collection; query generators created initial queries based on health consumer posts; ‘Terrier’ was used as the indexing technique. A set of different sources and methods were used to pick terms to be added to the initial queries:        

\textbf{Baseline}: 'BM25 term weighting model' was used to score and rank medical documents; ranking was performed based on documents' relevance to the issued search query 

\textbf{Pseudo Relevance feedback}: This method modified queries based on the top documents retrieved by the baseline approach; existing query terms were reweighted to pick useful terms and to drop useless terms. Two weighting models were used: the Bose-Einstein and the Kullback-Leibler Divergence; Bose-Einstein is based on the frequency of a query term in the top ranked documents; Kullback-Leibler Divergence is based on the probability of a query term in the top ranked documents. The most suitable model was determined by performing two runs.             

\textbf{Query expansion using the Medical Text Indexer}: This method linked query text to the Medical Subject Headings (MeSH) vocabulary; this provided with additional related concepts; all these concepts were appended to the initial query.  

\textbf{Query expansion using Wikipedia}: Wikipedia was chosen as a source because it contains health information and medical terms in lay language. Two methods were used to obtain expansion terms from Wikipedia; term frequency was used to extract the most frequent terms related to the MTI concepts, from the Wikipedia articles. The 5, 10 and 15 most frequent terms of each article were chosen; link analysis was used to identify similar articles to extract expansion terms from the titles of the articles. Jaccard similarity coefficient was used to filer out all the irrelevant articles. Titles of the articles with Jaccard similarity coefficient greater than 0.25, 0.50 and 0.75 were chosen.              
  
\textbf{Query expansion using MedlinePlus}: Information from the infoboxes of the Wikipedia pages were used to select related MedlinePlus pages. The sections, such as Causes, Symptoms, Treatment, Possible Complications and Alternative Names of the MedlinePlus pages were used for the query expansion process. The 5, 10 and 15 most frequent terms from each relevant section were chosen.       

\textbf{Query expansion using the ICD-10}: Information from the infoboxes of the Wikipedia pages were used to select related ICD-10 pages. Information regarding diseases or symptoms which are related to initial query concepts were used for query expansion process. The 5, 10 and 15 most frequent terms of an ICD-10 page were chosen to be appended with the original query.      

\textbf{Query expansion using Latent Dirichlet Allocation over Wikipedia}: This method generated different latent topics represented by the text in Wikipedia articles with different MTI concepts. A combination of 3 topics with 1, 5, 10 words and 1, 5, 10 topics with 5 words were chosen.     

\textbf{Query expansion using Unified Medical Language System}: This method extracted terms from the UMLS definitions which were related to the MTI concepts. The top 5, 10 and 15 most frequent terms related to each MTI concept were chosen from the UMLS definitions for query expansion.  

\textbf{Readability}: Three readability metrices representing the ‘educational grade level’ needed to understand a document were used; SMOG, FOG and Flesch-Kinciad. SMOG was calculated based on the 'number of polysyllable words in 30 sentences'; FOG was calculated based on the 'average sentence length' and the 'percentage of hard words'; Flesch-Kinciad was calculated based on the 'average sentence length' and the 'average number of syllables per word'. Three formulas with the combination of readability metrics and relevance scores were used to re-rank the documents retrieved using expanded queries; 

Three runs were submitted; firstly the Baseline approach; secondly the Wikipedia Link Analysis with a Jaccard similarity coefficient above 0.50; finally the Latent Dirichlet Allocation with 3 topics and 5 words. SMOG readability metric and one combination formula were used for re-ranking. However, because the unavailability of the relevance and readability assessments for the test collection at the time of reporting this study, it was impossible for the authors to compare results with the baseline for each sub task and to make any conclusions regarding the results which have been obtained by following different approaches.            

\textbf{Limitations}

One major limitation was the unavailability of the relevance and readability assessments for the test collection at the time of reporting the study. Another limitation was that Medical Text Indexer results were machine generated, so there was a possibility of generating irrelevant concepts.     

\section{Graham, L., Tse, T., \& Keselman, A. (2006). Exploring user navigation during online health information seeking. In AMIA Annual Symposium Proceedings (Vol. 2006, p. 299). American Medical Informatics Association.}

This study investigated user navigation behaviour while seeking for online health-related information. ClinicalTrials.gov web site's log data were obtained over a three month period; data was extracted from log files using Transaction Log Analysis (TLA); investigation focused on online search behaviour, query failures, navigation, browsing strategies, clicking on links, initiating queries, and task-oriented actions (logging into a system). Log data were parsed and converted to XML data structures; these structures included a client (a unique IP address), a session (a set of sequential actions performed during the search) and a request (a user action and its web server response). A Java program inserted all the useful log data (obtained by correcting erroneous session data and filtering web crawlers) into a MySQL database; temporary cookies were used to adjust the session boundaries; sessions without referring page or browser type were also removed. Web pages were aggregated into functional categories, such as search, browse, view results, view study etc. for the analysis; page reviews, referral frequencies, page transition frequencies (presented as a single transitions table by computing the frequencies), navigation path frequencies (determined using algorithms), click stream data, participant comments and usage statistics were assessed. Then a pilot user study was conducted; 7 lay consumers were presented with two hypothetical scenarios; ‘sleep apnea’ and ‘Parkinson’s disease’; they were assigned to either one of the scenarios to perform the search; any online resource could be used as their choice; TechSmith’s Morae™ was used to capture user-computer interactions and to record verbal responses.

By analysing ClinicalTrials.gov log data the authors observed that the ‘View Study' pages were the most frequently requested (40\%) and the most common entry and exit points to ClinicalTrials.gov; 'View Results' pages were the second most frequently requested (25\%); for 69\% of the sessions the initiation point was an external web site, such as search engines and government sites; the top five referring web sites were Google (41\%), NIH.gov domain (18\%), Yahoo, MSN and AIDSinfo which accounted for 66\% of all referrals; View Study (39\%), View Results and Opening Screen (homepage)  (24\%) pages served as web site entry and exit points; 
viewing two studies in a row or viewing a study and exiting (40\%), and clicking on a specific study in the results (9\%) list were the most frequent moves between pages indicating that users were moving among a limited set of pages (only a few user online navigation activities). 8 common user navigation patterns were identified; these patterns revealed that users were tend to access ClinicalTrials.gov directly via ‘View Study’ pages. Search and browse features were directly used; time was spent on exploring the site and refining search queries. Other available site features ‘Search within results’ and ‘Resources’ were not used.

The analysis of the pilot study revealed that 5 out of 7 consumers viewed at least one page at ClinicalTrials.gov during their session; two of them referred the web site directly from search engines, another two from MedlinePlus and one from a non-profit health Web site; the most frequent enter and exit point was ' View Results' page in contrast to TLA data with most frequent entry/exit point as 'View Study' page. For search queries with general terms users navigated to 'View results' page and for search queries with specific terms users navigated to 'View Study' page. The name recognition, “dot-gov” domains and keywords were used by participants to judge the relevance of the web sites; all the participants' were satisfied about the overall search task; pilot user study also had a similar structure of entry and exit points as the log data; most moves were occurred within the pages opening screen, view results and view study; external web sites, such as search engines have directed users to results pages and individual studies. 

The majority of the users are tend to refer to low-level pages (View Study) from external web sites, such as search engines. Therefore, it is worth placing links to background information and other search features on lower-level pages which are being directly accessed by users. Visible local maps retain users on web sites.

\section{Thenmozhi, D., Mirunalini, P., \& Aravindan, C. (2016). Decision Tree Approach for Consumer Health Information Search. In FIRE (Working Notes) (pp. 221-225).}

This study investigated how to determine sentences of a document is relevant, given a Consumer Health Information Search query and a document associated with the query. The approach of this study was to use a machine learning technique to categorize retrieved health-related information as relevant or irrelevant based on the issued query. A decision tree was created by following four steps; 1. preprocessing the given text by removing punctuations and adding annotations for parts of speech, such as nouns, verbs and adjectives. Nouns and adjectives were chosen as the features from the training data; 2. feature selection or extracting features for training data. Two variations were used; in the approach without feature selection, the linguistic features were used without explicit feature selection. The features were lemmatized to bring the features to their root form ; in the approach with χ 2 feature selection, a chi-square value was computed to pick the important features from the linguistic features. A maximum χ 2 statistic value was calculated to select the features with a strong dependency on the categories.The occurrence or non-occurrence of each feature in relevant and irrelevant instances were determined.The expected frequency for each feature was also calculated using the observed frequency; 3. using the selected features of training data to build a model using a classifier. For the approach without feature selection the features vector of training data was used to extract features from the test data with unknown labels. For the approach with feature selection, the features with  χ 2 statistic value greater than 3.841 were considered as significant features and were used to build the model; 4. predict the class label either as “relevant” or “irrelevant” for the instance using the built decision tree model. 
 
The data set consisted of five queries, and training and test data for each query. The number of nodes for the χ 2 feature selection tree were considerably lower than that of tree without feature selection; the reduction in size of the tree for χ 2 feature selection was statistically significant. The authors observed that the approach without feature selection had higher cross-validation accuracy for each query than for the approach with χ2 feature selection. However, χ2 feature selection method had a 2.23\% higher test data accuracy compared to the method without feature selection. The improvement in performance for the χ2 feature selection method was statistically significant. It was shown that the feature selection approach is able to significantly reduce the size of the model(decision tree) without compromising the performance. In conclusion, since χ2 feature selection model can categorize health-related documents as relevant and irrelevant successfully, it can be used for filtering out irrelevant health related documents prior presenting the results to consumers/ laypeople. This would help consumers in retrieving more relevant health related documents according to their issued query.

\end{document}